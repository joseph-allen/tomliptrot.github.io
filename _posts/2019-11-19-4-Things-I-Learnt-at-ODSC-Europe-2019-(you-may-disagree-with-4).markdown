---
layout: post
title: "4 Things I Learnt at ODSC Europe 2019 (you may disagree with 4)"
date:  2019-11-19 19:42:22
category:
---

![ODSC logo](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZcAAAB8CAMAAACSTA3KAAAA3lBMVEX///8EeNcAb9UAdNYAcdUActYAdtcAbdQQfdMSe84Ge9cMfdcSdsWpyu7v9/292fPD3fQQb7ri7voKabYAatSTuOmLuenz+P1Zlt/4/P620fDJ3vTx9/1Jkt7c6/mbwOt1quVeneHQ4/ZppOOItugzhtuvze9/suc+i9yhxe3b7Pmw1fNjoOJ1puOWv+sqg9orj943mOFRo+Saye9ztumGv+yhzfC62/QAc8tirOYAYtIAbsNDh8VckskAZLemwN0/jNJkmtIAXavN2OZ1nctHnuIokt98uuo6ergof8fy8wG7AAAVRUlEQVR4nO1da5ubOLJukEAJxNihfcUBG1/aOO2Y7qSTdCYzszuzOzO7//8PHSRxEbpws6dzznN4PyVWSwi9UlWpVCpubnr06NGjR48ePXr06NGjR48ePXr06NGjR48ePXr0+D+OhRsslxv33Y/uRw8Wy208RrqOEPTPzo/uTI8UQaQDU6MwITz86P70IBiMM1IooL25XuPvXFctHCsL/79jrRM2ANR1aBCGTORdq/HlTwihnxbywiEuhK3k5iwIlt55ethNj8NN4F6ji63gJM8fep633ATBrEvdwfF8Pt4lfQ8Ug5JhjTAVhnkaLJfDqQ8B/i8adu55GWcDN6coXCWFZtS4LcdbRzZCyewxgGHARBuCfXRW9NQZjigSaybB++D9exfDSTBbLGoGRYpgEEZW8nwdQvxwaEf+sekEHh39SMN9p8DV42h7p55YR50skF02a4M54QkGHTouwYeEZnBSFM6T1WnOmzUUTOwxBGWBm9Q2DX3sHyWvN/xJT4EkGBMgf33eNFyu7kFD0DS5p0N9HJ3rhmrmncY6XxfXBhDph6V0imzG+C9s9sUGeMWY+2bdrUOU9AZ8UBRaeKGumjRzjJDBv1fxglAPhXk70lV/ztYEBtLmMlo5LOfIULVhoGhVQW6w1nSg7gJA8U5SG4+bGZcLlpgreKwfrQZAFU05uF+wXhLMdiZUkpIOjm4NypUa8ULrQrgfVMo110eVz8cTQ2EqbfwqUmhtQ9/yM2OEx03nfz3C5Fe7iwgW3gi3jxR9XuKhQ+/r2liZsMnw6nGJ4ea8kIE1D+pFs6od2mTaj2XMuGE1oXlt/VAe7VPyRHgW2vOT1vRr2GR3eEgNhQD2cOG4poWl3YgVPLi6z4xtK15wJ42tXBgt/GYtAbjlDbQdrCc0e7zG2i8LWysWhhda4ZL+cwgrtHUbEIsrVhSuQUVh2sH1uNGEy4amkJhtecGTdicREe6+8dgCrTSVg33TGUWAtsXTsZgBa/rvbTICYJyuHfKHtaNej0ezwhIOzeLpcgRxq1dL+pybGO15wRtqweh27Ma04Mfvipp3dTqRh2Hly32DcsW7QrRlKiWxfLsGL3g9qoZ+EScdN0QhWsBrs1go4D71H3ThRTPHW66PzVcLAcrrH1D7p+c2EBb/kDKRlqU2LZY/6HLFTy2ugbzwHbE5lurax/avlrxAavN34iXpbFTS/6HKOlYAjdKKp06PR6kcPua8LNKSVKtciZcN7p0+UhQSW01tBnWYcRimRsyMjrwkI8DYVYOWXQBhWjFsKX8zjCkxK9V6mRhXkWPU4lLwS6zxWOlkOnQdWM3CxHTmxS6096ydECtm2akjLSCVZHjc0n+uaVOIyhWskq/AC7a4NKgonGBzzFdVnXZbLQks61VwCS/2c0bMrqUUM9ITkg8dn50b+gG2x1JVFSX2g4nW9D9V49kCYZUDDG+SwFZReDeuegFTcDYxsOxXz253XnB1OjkXsmITEMej3CtEF/+5ckop+w5Arohn2F7SUgtm4tvzu3RUYMWQNccixo9THbPhyQjv5GVL1ajiYQFaHMc2MBSDkwzs6zczgRcTAGAyUA5cUv07UVF3YicMGB+Og8HgOPE1yBvC+rGm70mPgR3He/ISXGUThcy+Fs9ZIx+4XBHszau4+t8RR5vCHJthwQnl5thMNaVQtB5mjht3OfWhRNIQXn4ecSLe9A/rUzjP4Ee2oXCFWvbrN2/wzJ8LHmCwY8yU94M5YB+SunpVSgno0XSZDf17bx0j9g9hzFhHywfs0RX9VztYuxFvhCWxuBReGDJwikOxufTdAFrzPXV3QFCxhJfbn7lBFVbmO2ez8seSzZ+NF8wvN9TnWnp+zBuPzsoqHGBjOsdO0r4b6MCNw2K5HWd/mu/nMWaH/R4LGs20ys8j1iFSTPM2wOaeBhSWMLHVgLRIunEx4VpG4uJscgNBeHl7y1WXL9vFINJ5Zkj9X/9BnFGlDsQyw9Lz0wZSG9mTmWImPMjqOgeDnkKyIsz78+HhYW+bpBq7xSCWEFAaSi1wABVeGFL4ICtxZDMO7lVBB25YprENLwmGe14fWLj+74spJyNVjtxhTBpI559liX03YlXfgzkyocU0/P7b4+PjnwkvMXk63GarbBiRA0ytS7SSOyxhhK0KMxoNZRiRk5+wVJg+cyvhRVedrWGsSnO0JS/J8uT0jPUKC8JfQm4hydc2aSBZsqmWnmq20HdYZUF5GuNTW3z6+PGPPxJeHkY3H8hsA3A/ScyMtUUErgk6RcQcx3oJpFemLocpFI6ppRFIJAGcVj64pORb83ITxKWZIG+gKhDBSVQFEVSObdv8gtHXTcdv8/TtW0LM4wMx7FJ/R2LFwfS8wAQVXqsKHDtuc7MXoLxIlguqO2xeMnXa83Izi0oyqzUvSQeoLJpaNi/I4Lrh6Dmfnp4wMY9PqdzwUHkkoGB3NMRVeHFFpd8g0pDZrnTg5Wbhs0NgY0H2lu+F3WAEnl+94haMIQixmSOPtPj8+a+/El6+FaLq3bow5U2oVcuMClzIC90xic6PRjbIKqezCy83jsVoE9qC0L16lesJvHBG3OYc7W0rjsI7jhvn/tOnhJinb/eln91JnEbwzI9tw9UKDDSrgJ0qQNuSQFoIiFUo4baRDRJmM74TL+Vlmmh+kZfqIzyCf75OeCkJstLuzYuT+W/SCKVxKdYiuL//khDz9EU2+N2i3dgGnBJIjNKW+zHFAo8iOJQL8eP5XUPjnZSbTfhuvNycGXOZCDJheqicRkUXnhNeSgvGYCQwF1UDYGGIOV+/3n9JiLlS0F41yKGYMjwMu2h0iatH2C43Dsg8w4t4Ic4nltpngRi0rp64g++vX3OCrJj/w9S1YILMNQajvHT5NVkwV4wKr4JbdR5J9DQUe7IQzH8ZeVJk7t+uvHjMgrGkvGiGVnkL5bc33HoxClXtUQc5RPvTh9CilhawMmKcr/ej7vqjHYhHAinC9UkAkyZOvw1vjbUI/EwXTFdebpgpgQXZa5GXpBkz9FSLZvH9Dbde9JxFcnKrQTuNzAzWxNACUdaW+3K3jvCZpyb1Kd2kJ2YSy3PCW2Mt4j4d8zJeGHOStCHjBfuFja0n3UhsfiW8FMTkx8o3N8TcgyVtQ/y268ZvdzXg/aHyUIzYBKH4u6Bexi0mEnXMd+bFYXjBgkzi6cqoMfcTUUD/4/ub8oIpPGrYQ6/pZbthSw7ZX0ipMCBvoHINkRgliU3AH1O2uIaRCcfOvLAHLliQSRRM0S9DH4ersv30223KS2Ypg0yIk5Ws8yt/XnmQ/reh6lDMJQfVot254HlRnnbK4KDLeGE8yBWCrOAGomjHzPe3b9+UBFkx5tixCgTRQdbntS60NMamyhyjMUqiiBLOYBuE+zMAl/Gy5BSMVPOXqTF0MMlG9m1GTMpLsRHFJngWpe1OdpNUPU1heYfzIiDmmKnwtBEVKwlQu+N3lXqr6UQEUXde3jNGB9laKjUMCwP5ZOG7tzkvVJDl8gBLgWzxTJEBYNoZ90cIssobfGtFjwRetFYu1B24iJcbwUfWLA7XhOZxcfOv329zQUZ4yYUFCWul2iXdxozpdMPhFeil9i0pyCU96XlkWii7RrbiebFb9ZrMhQt4Yf6etvKz1YyZZGfiZbwQQUZ+y3TPAOZRp3566EztITw9G7hDrwpiCe8Uhbh3hsRvzZ/dmvtWLjtC6wW8xAwLSSuvb//tag1jLk3j1W0hyAgvRsYLni70/tUidfaku2VS8LKKn4aMKzaFM+Idk9gEvJO/JS/ehbzseUH2243jNz+8+F5WMDkvJNqb/idKeaHm//TleQmqbvANSTy5pEMXrpfjlXn5/u/kx9244ZLBxLCWcs4L7lbq5lvTF0zv6OGtt8pT9TeBescU2kF5gfPMu2HsVtL3fCEv5Ue/evVMhs8NG9/He2Yt5Vy/4LEwqEifEblopB4oPA/ANe6xNscBKIYeg5hjMofkQBAarXiZXE/v00Dl1NLdbMcNQ8i/M4IsF9RYbGev64RjND7Rt9rA5vkLrgXiHZM4wAj2qpBxcf/Syk7eXmYnO3xYzHOuAp2z3WzR5IKM3RNjrZL/b/E+m63k1nGj/AXXA1Z8ypNXSzVQQrRiu/1+fNm+clN+OssLLl3bFckdcjYLi6x4/SOUhWuSMOF2L3g5iHdMcfAaAFWHhGCYVv4x6vXszgsnRS37mTNNgokNxGQoZRQKphBRM2KecRe801AP+/CSG0vqHatMqCDVHII/uU0+FOpd684LF7mWNCT+jeuFceWysQoFA/IRJyHfcMuumIBulux9/HCFUPCmoFNPoRyI1SVPqGDzb9xmO0x3P515Ec6wLfmkWLgrH6m1zZv8NBkVYd8RMcOYGOsjuYFjavH+4eHhY7c4yg6YViVU2CpDxuk5JovKi+Qc4svOxUbCGbY6km4xPFnCTQCK17kgY0wbeuHcRP7AdWbOZqqReWv4e/vh4c/Hx8enF0qlhv1ASlepr06oIBhkLQRZekjQmZeQnxOgMjBp5vlItmgYQQYLwZUmaDChrtkgTc6EwpvFNH54fPzj48ePX15kH0POIxXTbWGq14ErXIJrbrDMLzvfd4UrnbU35YNQltSi2PKzRrCQZ8ZEE/y78+3PhJdvCRT36a+JyhRWTpVNEAmX55qeJAepGOrKixCv3uRoZClxODMWWck2PrJ320yU39zbfMO8PD09farNLdUeoxKIo8X4NJJiSm+8ln7LWRI8MZre0FxJXehdeVkKroZGWz5nLxDDbPnLuapmKwtCkMDQQcRO2lGyWp7++vz5871gM8+81WF9OA+6ngZAxF5loe9oyG++pK479ieUaxFJOD9o1Kc8yqgjL7EwvqrD1jLE6zrsYTJvTm68D2EY7oZ80/dPCS+fPn36sinJzuF8DA1MJBxH3QLHhdFsBcY6EwSZJGJBgjw8uSMvW/EagcqLxIG/V5bwUsRdNj4mnt0nvHz5cn//tWAyYCOaTah12edcjRdPXDB6/aZ/EV/Gy1S8dE8PKbzay0ArntE3ZMGkN8dqbroxcO4/YVoKXu74dFLIb2+zdSQkBbubEQVKnmdIDcbG7cKLJOsJtTdmAJg1BqHgA39Tir5ocbHbvf9y/zXXtLs0rzVJaEs9DEAVvqoGTieRIz3EliMPa2dgMLyIvv5kxdTsLn1mznbgZS1JUUEz5ZBEbKfK0Tjy64ULI6ubVEtml+SORtmz6FSB9mHkOs5mFRGLvD0xLgsytHDkSkELN9yvTFOSBaOhKlHmlK5HtubFjSQzgSo1aqQZdtWSEUJ3uTCyGrtujdCe2blk406OdE14znkYko2peC2wDeh5pOKAlMhjvaL2UJZWAUbKc/AhaHCdWMnL4iD1QtKUVVmYhD5XPt0RSOXCyJKXFTKS5lhaBsmYyje/wPsi02J/XpCkZhelh9lVJVQIqwKY6F/I3BsmlKUFTWb7iaOxFS/uTpPGVVDBucrlm4lUiXyF5fL8thxGpuEFJx/NPI+vibhkHgdyIs490q9P1FqNvSJan7ZeFcBEuyt3CBrWVNjJBFvAjwvND/NLXX6YBJujD+Tnw4BMqtL5pQFOMheFmALuOw4j427CmNAXvSybk1E8wDBZFUquOSLeyzzD3vZLvmlBBkKVZdysKExxp8jgZaD5sfgOhLOZRhLPIQlk+YXPpwS2g+N5mmO3DiOE1ClbyQTgPDMAxdNNSSLNPFvg1czDyEo5FkxkHzbF/HeXu5i/ns/kIxmUEiW72Svj49xWNxzKcJXnkTdZCvKaoCllIkITwjgK14fDGn9bQqoZFPnHAIQGA1B17Dgmk3spzA7TQLa/uxttAuf9ZngMbdHVb/q//C4omLQHSIvm6wQnf6/p4vOZxNzYBZuN0SoGcZbYh7gQOvNCzyOr8ijVBk1FFUEO1MRWZna7MF8f7h2VeTK7kOQFoZ/I0KWrTb+7+c8tZykzlav7bo5p3iWcUC9bF1usgkCaFQgrbthZ8w+qErzjWKL6cL2Z1jp1cgbLxuESF/AypnZttywR9uLGvb19yyuYpviJXg0o8lsO6emDQYO5mYSkHXBShYflhfWup6AzMZaJJ1R3XtJkNO+6VcZmn3srF2T1SD1OmJf09CrVcemJAT7LaBQJJwWJ1ldtBGlChfpGgqrcolUAZD515mWcGm7rlslgCdLZGPyqEmTVyHbPDC/Z6QUNXb2IFxqVM1GUkgCmJksxsNqmLyYjY1DrsiMvQMvs2eqsrqrqqVJ1fxUtsnqgzFQmcoxylEbSp4Tjt6pNu6GCU3WDjwazNYr/cGT+kbqByWJwuvGiR8UOyWv74QN2b+H+93tbQWaifMCdIkA2oPoF0dVzvES/jGrNMa3hEQ+/la+F7mfj2oUXgEqLvPXXNMbMrmzxz+d2vACNmawkmSEdpCOCAKBUIZMLZl1DZ2hCBcXQk3VpNW3qTtjNV8FkDjvEzUdtbTTn3/jQaslwHv3zcxsFg0LWRF0zkcvuKtymS4ScjZpNB4/HuiqhAglgangSiDs1b/YlKAx9z+xWhYQmNTBRLNkXbOLmnykT8pJuouemCgZwQQxkByjewMCOw+4XmMlHX1T+6L0ioYISw1gRP8cBlr/8FrTiBeiRYre2kvs1BSBfEoWwsrUmvJjwxO+zY5mHcUCSHXWOAKwKUycuyZYWxV1cu2ZMCM5lwdmCF6DDD+p0ILOVVj8xoCl3+Dm7mihz/PixLz6dfhNxXfqNnH90Xy4kNE9ljgU1H32RY+gbFZLeBPpesOklcTXSqhBaW2WGpBSeD6oUDdCtibIFZ2dVfc4vmVDyTyyS74vAObMIp0S5SHJQNQRNJK6ILRooEirUwT0rQrUBHO8Psk8Ujo1qQIgQjE7HRolz3GNoIEPyfDP5OaxxWHknIPFSkr4j/6gKwiIeQpB9EcAZUOPwgrQlA3WC99Qm6OapfjdYg0TkGPlXKQDUDXBayRffbDepwCqBFzhtIrJmm8kWJI+EJKALh3QljzeiSZN8brPhJMZVma7jAL/1scJ9u6BJnQ0Qh9tTpNEFe8nhS4ggHCsPxXBh9y8wLobeNJzPfd+fz+cHb/jCOQkSG2voDc7bBOvdwBOi86qreoN19jmN7cob1vE5S7fVplnEqlwSwhx4d+oeb7y7O3lWtR4CtqUAMlOP+oH734GND40sBTyKuvrFelwfwSQE+JP0c5lt0+PH4mUzL/To0aNHjx49evTo0aNHjx49evTo0aNHjx49evTo0aNHjx49/gb8D6PTlwt8FiokAAAAAElFTkSuQmCC)



I went to the [Open Data Science Conference](https://odsc.com/london/) in London last week. I really enjoyed it. There was lost of really practical, technical content. Not too much bullshit/sales and lots of up to date data science. I would really recommend it as a data scientist going to get up to date with some of the latest stools and techniques people are using. Here are my four highlights:

## 1. NLP is having a pretty big moment:  we can all have a go!

![transformer](/assets/images/transformer.jpg)

There were quite a few good talks on NLP, mostly focusing on recent developments in deep neural networks - particularly large pre-trained transformer models. These models have been taking the NLP world by storm over the last couple of years, since the publishing of the seminal paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762) in late 2017. 

[Natasha Latysheva](https://www.linkedin.com/in/nslatysheva/) Machine Learning Engineer @ Welocalize gave a really tutorial on sequence modelling with deep learning. You can find the code related to it in this [Github Repo](https://github.com/nslatysheva/ODSC_Sequence_Modelling). It was pitched at just the right technical level (for me anyway). Quickly and clearly we were taken on a tour from feed forward Neural Nets to Recurrent NNs, GRU/LSTMs up to recent advances in encoder-decoders, Bi-RNNS, attention and transformers.

The tutorial took us through building a language model based on the Game of Thrones books. Where we built an LSTM model based on the text from the popular fantasy series. Here is a snippet of the model code, for making a LSTM model using keras:

```python
from keras.models import Sequential
from keras.layers import Embedding
from keras.layers import LSTM
from keras.layers import Dense

model = Sequential()
model.add(Embedding(vocabulary_size, 50, input_length=max_sequence_length-1))
model.add(LSTM(100, return_sequences=True))
model.add(LSTM(100))
model.add(Dense(100, activation='relu'))
model.add(Dense(vocabulary_size, activation='softmax'))
```

Here is a 'picture' of the model:

![model](/assets/images/bigger_network.png)

We looked at using the model generatively to simulate text from a 'seed' phrase. Here is an example where the seed phrase was.

> A dragon, the dead, and Tyrion walk into a...

and the output was:

> ... great roast of rubies the wind was the same and the way he had been a man of the harpy

This kind of thing can give you a good intuition for how the model is working. What you tend to find with LSTMs is that they while the do have some 'memory' going back few words, the topic quickly veers off from the starting point. 

Attention was designed as a way to improve this, and transformer models eventually did away with any recurrent layers replacing the whole thing with attention (and a few other bits and bobs...).These new models include BERT, XLNET, and GPT-2. GPT-2  is of fun to play with the GPT-2 transformer model here [https://talktotransformer.com/](https://talktotransformer.com/). I put in the start of this blog post and got this:

> **4 Things I Learnt at the open data science conference.**
>
> 1. You are using data that has been curated by scientists. Ideally, these scientists are trying to find new techniques, methods, or concepts.
>
> 2. Typically, these scientists are using tools and techniques in their own disciplines and institutions to make sense of the data.
>
> 3. You are relying on the original scientist to handcraft each piece of the analysis, so you have an opportunity to watch their previous work and learn something new.
> 4. Writing code

Which, kind of, makes sense - there is at least a thread running through the whole paragraph, that is related to the seed phrase. 

There was also this talk  ["Latest Deep Learning Models for NLP"](https://odsc.com/training/portfolio/latest-deep-learning-models-for-natural-language-processing/)  [github](https://github.com/AMDonati/ODSC2019-DL-models-NLP) , that I couldn't attend but is worth look.

## 2. I like Python *(mostly)*

![python](/assets/images/python.jpg)

After 10 years of using mostly R, lately I have been using more and more Python and I've really been enjoying it (with some misgivings that I won't go into here). So at this conference I tried to go to as many Python related talks as I could. It made me feel like a noob again, but was fun. Particularly good were there three

#### [Andreas Muller](https://amueller.github.io/): Professor at Columbia and developer of [scikit-learn](https://scikit-learn.org/stable/).

Was giving a series of talks on using the preeminent python machine learning library scikit-learn. I couldn't go to all of them (too much good stuff on!), but the one I went to was excellent. Its nice to hear directly from the developer of such a popular package. Like he said:

>  "I can ignore the warnings because I wrote them!"

It was good to get a bit of a break from neural nets and focus on what is sometimes (a bit disparagingly maybe?) called 'traditional machine learning'. This is actually the stuff that gets used by most data scientists in a commercial setting and getting and in depth tutorial by such an expert was really valuable. You can get the code for the whole series of tutorials  at this [github repo](https://github.com/amueller/ml-workshop-1-of-4). 

#### [Ian Ozvald](https://ianozsvald.com/), organiser of PyData London, and self-styled 'interim chief data scientist' on tools for higher performance Python. 

He had loads of tips for getting python code to run faster. More details are [here](https://ianozsvald.com/2019/11/22/higher-performance-python-odsc-2019/) These are the things I noted down:

- `%%timeit` for timing stuff in Jupyter

- `line_profiler` - profiling package. `LineProfiler`

- [Dask](https://dask.org/) - multicore vs distributed computing.. dask-ml for distributed sklearn ml. easy to parallelised Pandas functions. 

- [swifter](https://github.com/jmcarpenter2/swifter) - project for running code multicore. sits on dask. `df.swifter.apply`

- precompile functions with [numba](http://numba.pydata.org/)

- ```python
  import numba
  
  @numba.jit(nopython=True)
  def foo(row):
  	dostuff
  ```

- [shelve](https://docs.python.org/3/library/shelve.html) cache module

- [bulwark](https://pypi.org/project/bulwark/) - pandas testing/schema... have a look...

#### [Daniel Voigt Godoy](https://www.linkedin.com/in/dvgodoy/) from Deloitte, on Pytorch.

 [colab link](https://colab.research.google.com/github/dvgodoy/PyTorch101_ODSC_London2019/blob/master/PyTorch101_Colab.ipynb) [github](https://github.com/dvgodoy/PyTorch101_ODSC_London2019). He showed how to implement linear regression using gradient descent - uses all of pytorch's feature in simple example. A really useful introduction to the framework. I liked this image he used:

![img](http://karlstratos.com/drawings/linear_dogs.jpg)

[source](http://karlstratos.com/)

## 3. AI has a long way to go but DeepMind are doing amazing stuff

[Danilo  J Rezende](https://DaniloRezende.com), from DeepMind gave a fascinating talk on his research around model based reinforcement learning. I find this stuff really intresting, although I don't fully understand all (much?) of it. He was basically arguing why it is useful to learn generative models of the world. If we want really successful agents we will need to move beyond classification and  model the inputs, not just the outputs. To do this you need to understand causal structure. This sounds really truly to me. The general approach echoes stuff being put forward about how the human brain works by neuroscientist [Karl Friston](https://www.wired.com/story/karl-friston-free-energy-principle-artificial-intelligence/) and my favourite philosopher [Andy Clark](https://www.edge.org/conversation/andy_clark-perception-as-controlled-hallucination). There seems to be load of work around this area at the moment, and I'm keen to keep up with it. As yet it is mostly fairly theoretical without loads of applications, but I think that will change soon.

- paper:"[One-shot generalisation in deep generative models](https://arxiv.org/abs/1603.05106)", Danilo Rezend
- paper:"[neural scene representation and rendering](https://deepmind.com/blog/article/neural-scene-representation-and-rendering)": really interesting. Generative Query Network (GQN), . Filling in 3-d scenes from small number of images. Actions driven by reducing uncertainty (a la Friston). GQN, learns factorised representation of a scene. [full paper](https://storage.googleapis.com/deepmind-media/papers/Neural_Scene_Representation_and_Rendering_preprint.pdf)

## 4. *Vendors* don't really have anything very good to offer data science

IBMs 'keynote' talk was fairly dismal. I guess if you are the 'diamond' sponsor you get to do a sales pitch. Maybe it could be a bit better disguised. I'm never very impressed with Watson - its basically just branding of a fairly standard service. I once was pitched at by IBM and it was about 25 consultants in suits with 1 statistician on the phone suggesting to use a linear regression. Telling a room full of data scientists about how data can change our organisations is a bit reductive. 85% of statistics are made up on the spot. 

They were pitching their AutoAI product (along with most of the vendors here). I'm fairly sceptical about these. Such a small percentage of a data scientists time is spent running through various models to select the best. Professional data science is nothing like a kaggle competition where you are given a dataset nicely formatted in csv. The work is in understanding the business problem and how the data relates to it. Prediction is the quick bit at the end.

To be fair the organiser didn't look too happy with the talk.

All in, it was a really good conference and I reckon I'll be back next year in [Dublin](https://odsc.com/london/)



